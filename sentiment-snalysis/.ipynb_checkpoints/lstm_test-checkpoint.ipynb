{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 使用训练模型做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import pickle\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sen = '这节课好开心'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取停用词\n",
    "def StopWords():\n",
    "    with open('train_data/stopwords.txt','r',encoding = 'utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    stopWords = []\n",
    "    for line in lines:\n",
    "        stopWords.append(line)\n",
    "    return stopWords\n",
    "# 读取训练数据，并去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取训练数据，并去除停用词\n",
    "def read_data(input_sen):\n",
    "    sentence = []\n",
    "    trans = list(jieba.cut(input_sen.strip(), cut_all=False))\n",
    "\n",
    "    for word in trans:\n",
    "        if word not in stopWords:\n",
    "            sentence.append(word)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopWords = StopWords()\n",
    "word2vec_path = 'word2vec/word2vec.pkl' # 词向量地址\n",
    "file = open(word2vec_path, 'rb')\n",
    "word2vec_model = pickle.load(file )\n",
    "vector_size=word2vec_model.vector_size # 词向量的维度\n",
    "# 将输入数据处理成向量矩阵\n",
    "MAX_SIZE=25 # 句子的统一长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words2Array(line):\n",
    "    linesArray = []\n",
    "    wordsArray = []\n",
    "    steps = []\n",
    "\n",
    "    t = 0\n",
    "    p = 0\n",
    "    for i in range(MAX_SIZE):\n",
    "        # 如果小于MAX_SIZE 则用0.0的矩阵补齐\n",
    "        if i < len(line):\n",
    "            try:\n",
    "                wordsArray.append(word2vec_model.wv.word_vec(line[i]))\n",
    "                p = p + 1\n",
    "            except KeyError:\n",
    "                    # 如果在词向量模型中没有找到对应词的向量\n",
    "                t = t + 1\n",
    "                continue\n",
    "        else:\n",
    "            wordsArray.append(np.array([0.0] * vector_size))\n",
    "\n",
    "    for i in range(t):\n",
    "        wordsArray.append(np.array([0.0] * vector_size))\n",
    "    steps.append(p)\n",
    "    linesArray.append(wordsArray)\n",
    "\n",
    "    linesArray = np.array(linesArray)\n",
    "    steps = np.array(steps)\n",
    "    return linesArray, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 分词和去除停用词\n",
    "imput_data = read_data(input_sen)\n",
    "\n",
    "# 构造好输入数据\n",
    "data, steps = words2Array(imput_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model-senti\n",
      "[[0.7207277 0.2792723]]\n"
     ]
    }
   ],
   "source": [
    "num_nodes = 128  #\n",
    "batch_size = 1 # 一次喂给训练器的数据条数\n",
    "output_size = 2 # 输出的维度\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.import_meta_graph('model/model-senti.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\"model/\"))\n",
    "    prediction = tf.get_collection('pred_network')[0]\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    input_x = graph.get_operation_by_name('input_x').outputs[0]\n",
    "    input_steps = graph.get_operation_by_name('steps').outputs[0]\n",
    "\n",
    "    pre = sess.run(prediction, feed_dict={input_x:data, input_steps: steps})\n",
    "    print(pre)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子的情感极性：积极\n"
     ]
    }
   ],
   "source": [
    "if pre[0][0] > pre[0][1]:\n",
    "    print('句子的情感极性：积极')\n",
    "else:\n",
    "    print('句子的情感极性：消极')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
